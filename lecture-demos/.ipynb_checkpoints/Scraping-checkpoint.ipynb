{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cac465-66c1-4714-9126-22c1c7298527",
   "metadata": {},
   "source": [
    "## Scraping from a simple page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5979bad-ba22-41b6-a216-70c6f7c98901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:45:32.828173Z",
     "iopub.status.busy": "2025-07-10T08:45:32.826706Z",
     "iopub.status.idle": "2025-07-10T08:45:33.023229Z",
     "shell.execute_reply": "2025-07-10T08:45:33.021279Z",
     "shell.execute_reply.started": "2025-07-10T08:45:32.828116Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7b7af2-7eca-4340-8470-f2b90de22510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:45:34.394506Z",
     "iopub.status.busy": "2025-07-10T08:45:34.392701Z",
     "iopub.status.idle": "2025-07-10T08:45:34.399613Z",
     "shell.execute_reply": "2025-07-10T08:45:34.398120Z",
     "shell.execute_reply.started": "2025-07-10T08:45:34.394450Z"
    }
   },
   "outputs": [],
   "source": [
    "url = f\"https://wagon-public-datasets.s3.amazonaws.com/02-Data-Toolkit/02-Data-Sourcing/example.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d95a6e2-56f3-40af-8953-46688f77bad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:45:36.942790Z",
     "iopub.status.busy": "2025-07-10T08:45:36.941628Z",
     "iopub.status.idle": "2025-07-10T08:45:37.194299Z",
     "shell.execute_reply": "2025-07-10T08:45:37.192859Z",
     "shell.execute_reply.started": "2025-07-10T08:45:36.942738Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4452d336-6ea4-4c1b-8009-48c3bbaf8f2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:45:39.760616Z",
     "iopub.status.busy": "2025-07-10T08:45:39.759757Z",
     "iopub.status.idle": "2025-07-10T08:45:39.772120Z",
     "shell.execute_reply": "2025-07-10T08:45:39.771227Z",
     "shell.execute_reply.started": "2025-07-10T08:45:39.760570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Basic HTML example\\n  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You now can query the `soup` object!\n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7173f801-b402-47f0-9d00-d37bea52ec2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:45:51.149928Z",
     "iopub.status.busy": "2025-07-10T08:45:51.149200Z",
     "iopub.status.idle": "2025-07-10T08:45:51.160601Z",
     "shell.execute_reply": "2025-07-10T08:45:51.159162Z",
     "shell.execute_reply.started": "2025-07-10T08:45:51.149873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>My First Heading</h1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4736eafb-c499-4026-88b8-d306544612e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:46:06.408804Z",
     "iopub.status.busy": "2025-07-10T08:46:06.407194Z",
     "iopub.status.idle": "2025-07-10T08:46:06.418041Z",
     "shell.execute_reply": "2025-07-10T08:46:06.416822Z",
     "shell.execute_reply.started": "2025-07-10T08:46:06.408737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.lewagon.com\" id=\"author\">Le Wagon</a>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41413673-9972-4bcf-b53e-a5dd248f5b89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:46:27.331753Z",
     "iopub.status.busy": "2025-07-10T08:46:27.330787Z",
     "iopub.status.idle": "2025-07-10T08:46:27.340360Z",
     "shell.execute_reply": "2025-07-10T08:46:27.339012Z",
     "shell.execute_reply.started": "2025-07-10T08:46:27.331704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This is a very simple html page.</p>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = soup.find(\"p\")\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28cbbc5-f4ac-4df3-a89d-61a06dafd757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:46:33.559284Z",
     "iopub.status.busy": "2025-07-10T08:46:33.558582Z",
     "iopub.status.idle": "2025-07-10T08:46:33.569171Z",
     "shell.execute_reply": "2025-07-10T08:46:33.568004Z",
     "shell.execute_reply.started": "2025-07-10T08:46:33.559229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<article>How to load CSVs?</article>,\n",
       " <article>API calls with Python</article>,\n",
       " <article>Scraping with BeautifulSoup</article>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = soup.find_all(\"article\")\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ec9dad-4863-4eb3-8aac-008658fb22b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:46:38.458848Z",
     "iopub.status.busy": "2025-07-10T08:46:38.458225Z",
     "iopub.status.idle": "2025-07-10T08:46:38.469113Z",
     "shell.execute_reply": "2025-07-10T08:46:38.467525Z",
     "shell.execute_reply.started": "2025-07-10T08:46:38.458798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li class=\"package\">Pandas</li>,\n",
       " <li class=\"package\">Requests</li>,\n",
       " <li class=\"package\">BeautifulSoup</li>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = soup.find_all(\"li\", class_=\"package\")\n",
    "items\n",
    "# Mind the use of class_ instead of class!class is a reserved keyword in Python, so we can't use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4ba2d-d858-45d5-a009-2e5382de9715",
   "metadata": {},
   "source": [
    "## Let's scrape Wikipedia to enrich our data\n",
    "### Our goal: find the region of each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead3acfc-1139-4efb-b8d8-58109c68b86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:48:58.767096Z",
     "iopub.status.busy": "2025-07-10T08:48:58.766129Z",
     "iopub.status.idle": "2025-07-10T08:49:00.071443Z",
     "shell.execute_reply": "2025-07-10T08:49:00.070135Z",
     "shell.execute_reply.started": "2025-07-10T08:48:58.767044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Full Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "      <td>Åland Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "      <td>American Samoa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Code       Full Name\n",
       "0     Afghanistan   AF     Afghanistan\n",
       "1   Åland Islands   AX   Åland Islands\n",
       "2         Albania   AL         Albania\n",
       "3         Algeria   DZ         Algeria\n",
       "4  American Samoa   AS  American Samoa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!curl -s https://wagon-public-datasets.s3.amazonaws.com/02-Data-Toolkit/02-Data-Sourcing/iso2_codes.csv > data/iso2_codes.csv\n",
    "\n",
    "import pandas as pd\n",
    "iso_df = pd.read_csv('data/iso2_codes.csv', na_filter=False)\n",
    "iso_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696d50fe-883b-4e82-ada7-8c76493c2120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:49:03.415025Z",
     "iopub.status.busy": "2025-07-10T08:49:03.414324Z",
     "iopub.status.idle": "2025-07-10T08:49:03.432073Z",
     "shell.execute_reply": "2025-07-10T08:49:03.420494Z",
     "shell.execute_reply.started": "2025-07-10T08:49:03.414963Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86de2d02-c3b1-4c2c-8045-e1c69f5fc703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:51:30.756422Z",
     "iopub.status.busy": "2025-07-10T08:51:30.755114Z",
     "iopub.status.idle": "2025-07-10T08:51:31.029978Z",
     "shell.execute_reply": "2025-07-10T08:51:31.028598Z",
     "shell.execute_reply.started": "2025-07-10T08:51:30.756353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When you start scraping, get it working for one row.\n",
    "#Then refactor it to get all the data.\n",
    "\n",
    "# What does our URL look like?\n",
    "# We can find the region via this url: https://en.wikipedia.org/wiki/Geography_of_<Country_name>\n",
    "# Let's try with the best country ever - Belgium!\n",
    "url = \"https://en.wikipedia.org/wiki/Geography_of_Belgium\"\n",
    "# Get the response\n",
    "response = requests.get(url)\n",
    "# Turn it into Soup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# Find the infobox\n",
    "infobox = soup.find(class_=\"infobox-data\")\n",
    "# Extract the region\n",
    "region = infobox.text\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b8c8a1-d3c1-4c14-b7cc-095757767f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:51:33.473261Z",
     "iopub.status.busy": "2025-07-10T08:51:33.472408Z",
     "iopub.status.idle": "2025-07-10T08:51:33.477787Z",
     "shell.execute_reply": "2025-07-10T08:51:33.476940Z",
     "shell.execute_reply.started": "2025-07-10T08:51:33.473233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n"
     ]
    }
   ],
   "source": [
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6fcaf28-0135-4373-9c17-ace1ca8c900b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:52:20.047904Z",
     "iopub.status.busy": "2025-07-10T08:52:20.046694Z",
     "iopub.status.idle": "2025-07-10T08:52:20.055588Z",
     "shell.execute_reply": "2025-07-10T08:52:20.054085Z",
     "shell.execute_reply.started": "2025-07-10T08:52:20.047839Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's chain it now into a function!\n",
    "def region_scraper(country):\n",
    "    url = f\"https://en.wikipedia.org/wiki/Geography_of_{country}\"\n",
    "    print(f\"Scraping info for {country}\")\n",
    "    try:\n",
    "        # Get the response\n",
    "        response = requests.get(url)\n",
    "        # Turn it into Soup\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # Find the infobox\n",
    "        infobox = soup.find(class_=\"infobox-data\")\n",
    "        # Extract the region\n",
    "        region = infobox.text\n",
    "        return region\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1862f446-9646-4959-8ed2-1e0fe2630b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:54:03.744419Z",
     "iopub.status.busy": "2025-07-10T08:54:03.743452Z",
     "iopub.status.idle": "2025-07-10T08:54:04.011298Z",
     "shell.execute_reply": "2025-07-10T08:54:04.009593Z",
     "shell.execute_reply.started": "2025-07-10T08:54:03.744368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping info for Indonesia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Asia and Oceania'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_scraper(\"Indonesia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac2daec6-0737-459d-a526-55411ab165bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:54:08.487793Z",
     "iopub.status.busy": "2025-07-10T08:54:08.487145Z",
     "iopub.status.idle": "2025-07-10T08:56:51.819302Z",
     "shell.execute_reply": "2025-07-10T08:56:51.818404Z",
     "shell.execute_reply.started": "2025-07-10T08:54:08.487735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping info for Afghanistan\n",
      "Scraping info for Åland Islands\n",
      "Scraping info for Albania\n",
      "Scraping info for Algeria\n",
      "Scraping info for American Samoa\n",
      "Scraping info for Andorra\n",
      "Scraping info for Angola\n",
      "Scraping info for Anguilla\n",
      "Scraping info for Antarctica\n",
      "Scraping info for Antigua and Barbuda\n",
      "Scraping info for Argentina\n",
      "Scraping info for Armenia\n",
      "Scraping info for Aruba\n",
      "Scraping info for Australia\n",
      "Scraping info for Austria\n",
      "Scraping info for Azerbaijan\n",
      "Scraping info for Bahamas\n",
      "Scraping info for Bahrain\n",
      "Scraping info for Bangladesh\n",
      "Scraping info for Barbados\n",
      "Scraping info for Belarus\n",
      "Scraping info for Belgium\n",
      "Scraping info for Belize\n",
      "Scraping info for Benin\n",
      "Scraping info for Bermuda\n",
      "Scraping info for Bhutan\n",
      "Scraping info for Bolivia\n",
      "Scraping info for Bolivia\n",
      "Scraping info for Bonaire\n",
      "Scraping info for Bosnia and Herzegovina\n",
      "Scraping info for Botswana\n",
      "Scraping info for Bouvet Island\n",
      "Scraping info for Brazil\n",
      "Scraping info for British Indian Ocean Territory\n",
      "Scraping info for Brunei Darussalam\n",
      "Scraping info for Brunei\n",
      "Scraping info for Bulgaria\n",
      "Scraping info for Burkina Faso\n",
      "Scraping info for Burundi\n",
      "Scraping info for Cambodia\n",
      "Scraping info for Cameroon\n",
      "Scraping info for Canada\n",
      "Scraping info for Cape Verde\n",
      "Scraping info for Cayman Islands\n",
      "Scraping info for Central African Republic\n",
      "Scraping info for Chad\n",
      "Scraping info for Chile\n",
      "Scraping info for China\n",
      "Scraping info for Christmas Island\n",
      "Scraping info for Cocos (Keeling) Islands\n",
      "Scraping info for Colombia\n",
      "Scraping info for Comoros\n",
      "Scraping info for Congo\n",
      "Scraping info for Republic of the Congo\n",
      "Scraping info for Democratic Republic of the Congo\n",
      "Scraping info for Democratic Republic of the Congo\n",
      "Scraping info for Cook Islands\n",
      "Scraping info for Costa Rica\n",
      "Scraping info for Côte d'Ivoire\n",
      "Scraping info for Cote d'Ivoire\n",
      "Scraping info for Croatia\n",
      "Scraping info for Cuba\n",
      "Scraping info for Curaçao\n",
      "Scraping info for Cyprus\n",
      "Scraping info for Czech Republic\n",
      "Scraping info for Denmark\n",
      "Scraping info for Djibouti\n",
      "Scraping info for Dominica\n",
      "Scraping info for Dominican Republic\n",
      "Scraping info for Ecuador\n",
      "Scraping info for Egypt\n",
      "Scraping info for El Salvador\n",
      "Scraping info for Equatorial Guinea\n",
      "Scraping info for Eritrea\n",
      "Scraping info for Estonia\n",
      "Scraping info for Ethiopia\n",
      "Scraping info for Falkland Islands (Malvinas)\n",
      "Scraping info for Faroe Islands\n",
      "Scraping info for Fiji\n",
      "Scraping info for Finland\n",
      "Scraping info for France\n",
      "Scraping info for French Guiana\n",
      "Scraping info for French Polynesia\n",
      "Scraping info for French Southern Territories\n",
      "Scraping info for Gabon\n",
      "Scraping info for Gambia\n",
      "Scraping info for Georgia\n",
      "Scraping info for Germany\n",
      "Scraping info for Ghana\n",
      "Scraping info for Gibraltar\n",
      "Scraping info for Greece\n",
      "Scraping info for Greenland\n",
      "Scraping info for Grenada\n",
      "Scraping info for Guadeloupe\n",
      "Scraping info for Guam\n",
      "Scraping info for Guatemala\n",
      "Scraping info for Guernsey\n",
      "Scraping info for Guinea\n",
      "Scraping info for Guinea-Bissau\n",
      "Scraping info for Guyana\n",
      "Scraping info for Haiti\n",
      "Scraping info for Heard Island and McDonald Islands\n",
      "Scraping info for Holy See (Vatican City State)\n",
      "Scraping info for Honduras\n",
      "Scraping info for Hong Kong\n",
      "Scraping info for Hong Kong\n",
      "Scraping info for Hungary\n",
      "Scraping info for Iceland\n",
      "Scraping info for India\n",
      "Scraping info for Indonesia\n",
      "Scraping info for Iran\n",
      "Scraping info for Iran\n",
      "Scraping info for Iraq\n",
      "Scraping info for Ireland\n",
      "Scraping info for Isle of Man\n",
      "Scraping info for Israel\n",
      "Scraping info for Italy\n",
      "Scraping info for Jamaica\n",
      "Scraping info for Japan\n",
      "Scraping info for Jersey\n",
      "Scraping info for Jordan\n",
      "Scraping info for Kazakhstan\n",
      "Scraping info for Kenya\n",
      "Scraping info for Kiribati\n",
      "Scraping info for North Korea\n",
      "Scraping info for South Korea\n",
      "Scraping info for Kuwait\n",
      "Scraping info for Kyrgyzstan\n",
      "Scraping info for Kyrgyz Republic\n",
      "Scraping info for Lao People's Democratic Republic\n",
      "Scraping info for Lao\n",
      "Scraping info for Latvia\n",
      "Scraping info for Lebanon\n",
      "Scraping info for Lesotho\n",
      "Scraping info for Liberia\n",
      "Scraping info for Libya\n",
      "Scraping info for Liechtenstein\n",
      "Scraping info for Lithuania\n",
      "Scraping info for Luxembourg\n",
      "Scraping info for Macao\n",
      "Scraping info for Macedonia\n",
      "Scraping info for North Macedonia\n",
      "Scraping info for Madagascar\n",
      "Scraping info for Malawi\n",
      "Scraping info for Malaysia\n",
      "Scraping info for Maldives\n",
      "Scraping info for Mali\n",
      "Scraping info for Malta\n",
      "Scraping info for Marshall Islands\n",
      "Scraping info for Martinique\n",
      "Scraping info for Mauritania\n",
      "Scraping info for Mauritius\n",
      "Scraping info for Mayotte\n",
      "Scraping info for Mexico\n",
      "Scraping info for Micronesia\n",
      "Scraping info for Micronesia\n",
      "Scraping info for Moldova\n",
      "Scraping info for Moldova\n",
      "Scraping info for Monaco\n",
      "Scraping info for Mongolia\n",
      "Scraping info for Montenegro\n",
      "Scraping info for Montserrat\n",
      "Scraping info for Morocco\n",
      "Scraping info for Mozambique\n",
      "Scraping info for Myanmar\n",
      "Scraping info for Namibia\n",
      "Scraping info for Nauru\n",
      "Scraping info for Nepal\n",
      "Scraping info for Netherlands\n",
      "Scraping info for New Caledonia\n",
      "Scraping info for New Zealand\n",
      "Scraping info for Nicaragua\n",
      "Scraping info for Niger\n",
      "Scraping info for Nigeria\n",
      "Scraping info for Niue\n",
      "Scraping info for Norfolk Island\n",
      "Scraping info for Northern Mariana Islands\n",
      "Scraping info for North Korea\n",
      "Scraping info for Norway\n",
      "Scraping info for Oman\n",
      "Scraping info for Pakistan\n",
      "Scraping info for Palau\n",
      "Scraping info for Palestine\n",
      "Scraping info for Palestine\n",
      "Scraping info for Panama\n",
      "Scraping info for Papua New Guinea\n",
      "Scraping info for Paraguay\n",
      "Scraping info for Peru\n",
      "Scraping info for Philippines\n",
      "Scraping info for Pitcairn\n",
      "Scraping info for Poland\n",
      "Scraping info for Portugal\n",
      "Scraping info for Puerto Rico\n",
      "Scraping info for Qatar\n",
      "Scraping info for Réunion\n",
      "Scraping info for Romania\n",
      "Scraping info for Russian Federation\n",
      "Scraping info for Russia\n",
      "Scraping info for Rwanda\n",
      "Scraping info for Saint Barthélemy\n",
      "Scraping info for Saint Helena\n",
      "Scraping info for Saint Kitts and Nevis\n",
      "Scraping info for St. Kitts and Nevis\n",
      "Scraping info for Saint Lucia\n",
      "Scraping info for St. Lucia\n",
      "Scraping info for Saint Martin (French part)\n",
      "Scraping info for Saint Pierre and Miquelon\n",
      "Scraping info for Saint Vincent and the Grenadines\n",
      "Scraping info for St. Vincent and the Grenadines\n",
      "Scraping info for Samoa\n",
      "Scraping info for San Marino\n",
      "Scraping info for Sao Tome and Principe\n",
      "Scraping info for Saudi Arabia\n",
      "Scraping info for Senegal\n",
      "Scraping info for Serbia\n",
      "Scraping info for Seychelles\n",
      "Scraping info for Sierra Leone\n",
      "Scraping info for Singapore\n",
      "Scraping info for Sint Maarten (Dutch part)\n",
      "Scraping info for Slovakia\n",
      "Scraping info for Slovak Republic\n",
      "Scraping info for Slovenia\n",
      "Scraping info for Solomon Islands\n",
      "Scraping info for Somalia\n",
      "Scraping info for South Africa\n",
      "Scraping info for South Georgia and the South Sandwich Islands\n",
      "Scraping info for South Korea\n",
      "Scraping info for South Sudan\n",
      "Scraping info for Spain\n",
      "Scraping info for Sri Lanka\n",
      "Scraping info for Sudan\n",
      "Scraping info for Suriname\n",
      "Scraping info for Svalbard and Jan Mayen\n",
      "Scraping info for Eswatini\n",
      "Scraping info for Sweden\n",
      "Scraping info for Switzerland\n",
      "Scraping info for Syrian Arab Republic\n",
      "Scraping info for Syria\n",
      "Scraping info for Taiwan\n",
      "Scraping info for Taiwan\n",
      "Scraping info for Tajikistan\n",
      "Scraping info for Tanzania\n",
      "Scraping info for Tanzania\n",
      "Scraping info for Thailand\n",
      "Scraping info for Timor-Leste\n",
      "Scraping info for Togo\n",
      "Scraping info for Tokelau\n",
      "Scraping info for Tonga\n",
      "Scraping info for Trinidad and Tobago\n",
      "Scraping info for Tunisia\n",
      "Scraping info for Turkey\n",
      "Scraping info for Turkmenistan\n",
      "Scraping info for Turks and Caicos Islands\n",
      "Scraping info for Tuvalu\n",
      "Scraping info for Uganda\n",
      "Scraping info for Ukraine\n",
      "Scraping info for United Arab Emirates\n",
      "Scraping info for UAE\n",
      "Scraping info for United Kingdom\n",
      "Scraping info for United Kingdom\n",
      "Scraping info for United States\n",
      "Scraping info for United States\n",
      "Scraping info for United States Minor Outlying Islands\n",
      "Scraping info for Uruguay\n",
      "Scraping info for Uzbekistan\n",
      "Scraping info for Vanuatu\n",
      "Scraping info for Venezuela\n",
      "Scraping info for Venezuela\n",
      "Scraping info for Viet Nam\n",
      "Scraping info for Vietnam\n",
      "Scraping info for Virgin Islands\n",
      "Scraping info for Virgin Islands\n",
      "Scraping info for Wallis and Futuna\n",
      "Scraping info for Western Sahara\n",
      "Scraping info for Yemen\n",
      "Scraping info for Zambia\n",
      "Scraping info for Zimbabwe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                   Asia\n",
       "1                   None\n",
       "2                 Europe\n",
       "3                 Africa\n",
       "4       United States[a]\n",
       "             ...        \n",
       "272               France\n",
       "273               Africa\n",
       "274                 Asia\n",
       "275               Africa\n",
       "276               Africa\n",
       "Name: Full Name, Length: 277, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now get all the regions with Series.map()\n",
    "# a pandas method that applies a function (or mapping) element by element to a Series.\n",
    "regions = iso_df['Full Name'].map(region_scraper)\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cbccf56-9910-4abd-921c-a333dccfb916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:57:05.843943Z",
     "iopub.status.busy": "2025-07-10T08:57:05.843287Z",
     "iopub.status.idle": "2025-07-10T08:57:05.852597Z",
     "shell.execute_reply": "2025-07-10T08:57:05.850931Z",
     "shell.execute_reply.started": "2025-07-10T08:57:05.843884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now that we know it works, we can assign the result to a new column in our DataFrame.\n",
    "iso_df['Region'] = regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b14b068-d034-4958-8dba-30eed8a6b726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:57:13.993711Z",
     "iopub.status.busy": "2025-07-10T08:57:13.993351Z",
     "iopub.status.idle": "2025-07-10T08:57:13.999864Z",
     "shell.execute_reply": "2025-07-10T08:57:13.999129Z",
     "shell.execute_reply.started": "2025-07-10T08:57:13.993680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "iso_df['Region'].isnull().sum()\n",
    "#Our scraping has missed quite a few regions ... it's not always reliable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b547d3-561b-4706-a495-538c215d49b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:59:03.711279Z",
     "iopub.status.busy": "2025-07-10T08:59:03.710901Z",
     "iopub.status.idle": "2025-07-10T08:59:03.722015Z",
     "shell.execute_reply": "2025-07-10T08:59:03.721182Z",
     "shell.execute_reply.started": "2025-07-10T08:59:03.711250Z"
    }
   },
   "outputs": [],
   "source": [
    "# It's good practice to save your data so you don't have to scrape it again.\n",
    "iso_df.to_csv(\"countries_regions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e66a7e1-2fb4-4836-9d53-8ec92c16cc94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T08:59:04.215774Z",
     "iopub.status.busy": "2025-07-10T08:59:04.214801Z",
     "iopub.status.idle": "2025-07-10T08:59:04.369337Z",
     "shell.execute_reply": "2025-07-10T08:59:04.366877Z",
     "shell.execute_reply.started": "2025-07-10T08:59:04.215664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Code,Full Name,Region\n",
      "Afghanistan,AF,Afghanistan,Asia\n"
     ]
    }
   ],
   "source": [
    "# check the output\n",
    "!head -n 2 countries_regions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977f332-7076-4232-8c13-ae7273b2d95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
